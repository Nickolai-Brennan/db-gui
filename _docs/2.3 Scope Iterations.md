I’m choosing (1) 2.3 scope iteration — it’s the biggest “turn this into a product” step because it makes SQL checks work correctly for diagram / schema / table scopes and produces table- and relationship-targeted issues that your ERD can jump to.

Below is an implementation-ready bundle:

✅ build a run plan per node based on scope_type + target_selector

✅ iterate tables/schemas safely

✅ run SQL template per scope with ctx.schema/ctx.table

✅ aggregate outputs + targets into the instance result row

✅ keep limits (timeout + row cap)

✅ works with your existing runSqlCheck() + mapping logic



---

1) Introspection helper (get tables list once)

apps/api/src/sqlrunner/introspectTables.ts

import type { Pool } from 'pg';

export type TableRef = { schema: string; table: string };

export async function listTables(pool: Pool, schemas: string[]): Promise<TableRef[]> {
  const res = await pool.query(
    `
    SELECT n.nspname AS schema, c.relname AS table
    FROM pg_class c
    JOIN pg_namespace n ON n.oid = c.relnamespace
    WHERE c.relkind IN ('r','p')
      AND n.nspname = ANY($1::text[])
    ORDER BY 1,2
    `,
    [schemas],
  );

  return (res.rows ?? []).map((r: any) => ({ schema: r.schema, table: r.table }));
}


---

2) Target selector → run plan

We’ll support minimal selectors now (enough to ship):

{ kind: "all" } → run once

{ kind: "allSchemas" } → run once per schema

{ kind: "allTables" } → run once per table

{ kind: "tablesBySchema", schema: "public" }

{ kind: "tablesByRegex", pattern: "^dim_" } (applies to table name; optional schema too)


apps/api/src/sqlrunner/plan.ts

import type { TableRef } from './introspectTables';

export type TargetSelector =
  | { kind: 'all' }
  | { kind: 'allSchemas' }
  | { kind: 'allTables' }
  | { kind: 'tablesBySchema'; schema: string }
  | { kind: 'tablesByRegex'; pattern: string; schema?: string };

export type ScopeType = 'diagram' | 'schema' | 'table';

export type RunUnit =
  | { unit: 'diagram' }
  | { unit: 'schema'; schema: string }
  | { unit: 'table'; schema: string; table: string };

export function buildRunPlan(args: {
  scopeType: ScopeType;
  schemas: string[];
  selector: TargetSelector | null;
  tables: TableRef[];
}): RunUnit[] {
  const { scopeType, schemas, selector, tables } = args;

  // If node doesn't specify selector, default based on scopeType
  const sel: TargetSelector =
    selector ??
    (scopeType === 'diagram'
      ? { kind: 'all' }
      : scopeType === 'schema'
        ? { kind: 'allSchemas' }
        : { kind: 'allTables' });

  // ScopeType acts as a ceiling (don’t run table-level units for schema-scoped nodes unless selector says so)
  // For v1: selector drives. scopeType is informational but still used for default.

  if (sel.kind === 'all') return [{ unit: 'diagram' }];

  if (sel.kind === 'allSchemas') {
    return schemas.map((s) => ({ unit: 'schema', schema: s }));
  }

  const matchTables = (): TableRef[] => {
    if (sel.kind === 'allTables') return tables;

    if (sel.kind === 'tablesBySchema') return tables.filter((t) => t.schema === sel.schema);

    if (sel.kind === 'tablesByRegex') {
      const re = new RegExp(sel.pattern);
      return tables.filter((t) => (sel.schema ? t.schema === sel.schema : true) && re.test(t.table));
    }

    return tables;
  };

  return matchTables().map((t) => ({ unit: 'table', schema: t.schema, table: t.table }));
}


---

3) Run a SQL node across its plan + aggregate outputs

Aggregation strategy (ship-safe):

Each unit returns up to rowCap rows; we store:

output_summary: counts + first few failures

output_stats: totalFailUnits, totalRows, unitsRun

output_rows: a small sample across units (cap 50)

target_ref.targets: unique union (cap 200)



apps/api/src/sqlrunner/runSqlNode.ts

import type { Pool } from 'pg';
import type { TargetSelector, ScopeType, RunUnit } from './plan';
import { buildRunPlan } from './plan';
import { listTables } from './introspectTables';
import { runSqlCheck } from './runSqlCheck';
import { evaluateRule } from './evaluate';
import type { ResultMapping } from './mapping';

export type SqlNodeInput = {
  targetPool: Pool;
  sqlTemplate: string;
  schemas: string[];
  scopeType: ScopeType;                // node scope_type
  targetSelector: TargetSelector | null; // node target_selector
  passFailRule: any;                   // node pass_fail_rule
  resultMapping: ResultMapping | null; // node result_mapping

  limits?: { timeoutMs?: number; rowCap?: number };
  thresholds?: Record<string, number>;
  vars?: Record<string, any>;
};

export type SqlNodeOutput = {
  status: 'pass' | 'warning' | 'fail' | 'blocked';
  violationsCount: number;
  outputSummary: string;
  outputStats: any;
  outputRows: any[];
  targetRefs: any[]; // targets[]
};

export async function runSqlNode(input: SqlNodeInput): Promise<SqlNodeOutput> {
  const timeoutMs = input.limits?.timeoutMs ?? 2500;
  const rowCap = input.limits?.rowCap ?? 50;

  // 1) One introspection call per node run (fast enough)
  const tables = await listTables(input.targetPool, input.schemas);

  // 2) Build run plan (diagram/schema/table units)
  const plan = buildRunPlan({
    scopeType: input.scopeType,
    schemas: input.schemas,
    selector: input.targetSelector,
    tables,
  });

  // 3) Execute units
  let totalRows = 0;
  let failingUnits = 0;
  const sampleRows: any[] = [];
  const targets: any[] = [];
  const seenTargets = new Set<string>();

  const unitSummaries: string[] = [];

  for (const unit of plan) {
    const ctx = {
      schemas: input.schemas,
      schema: unit.unit === 'schema' || unit.unit === 'table' ? unit.schema : undefined,
      table: unit.unit === 'table' ? unit.table : undefined,
      thresholds: input.thresholds ?? {},
      vars: input.vars ?? {},
    };

    const res = await runSqlCheck({
      pool: input.targetPool,
      template: input.sqlTemplate,
      ctx,
      limits: { timeoutMs, rowCap },
      mapping: input.resultMapping,
    });

    const rowCount = res.rows.length;
    totalRows += rowCount;

    const evalRes = evaluateRule(input.passFailRule, rowCount);
    const passed = evalRes.passed;

    if (!passed) failingUnits += 1;

    // sample some rows across units (cap 50 overall)
    for (const r of res.rows) {
      if (sampleRows.length >= 50) break;
      // tag unit context so UI can show where it came from
      sampleRows.push({
        __unit: unit.unit,
        __schema: (unit as any).schema,
        __table: (unit as any).table,
        ...r,
      });
    }

    // union targets (cap 200)
    for (const t of res.targetRef.targets ?? []) {
      if (targets.length >= 200) break;
      const sig =
        t.kind === 'table'
          ? `t:${t.schema}.${t.table}`
          : t.kind === 'column'
            ? `c:${t.schema}.${t.table}.${t.column}`
            : `r:${t.childSchema}.${t.childTable}(${(t.childCols ?? []).join(',')})->${t.parentSchema}.${t.parentTable}(${(t.parentCols ?? []).join(',')})`;
      if (seenTargets.has(sig)) continue;
      seenTargets.add(sig);
      targets.push(t);
    }

    if (!passed) {
      const label =
        unit.unit === 'diagram' ? 'diagram' : unit.unit === 'schema' ? `${unit.schema}` : `${unit.schema}.${unit.table}`;
      unitSummaries.push(`${label}: ${rowCount} rows (${evalRes.reason})`);
    }

    // Early exit option (optional): if huge failures, stop
    // if (failingUnits >= 200) break;
  }

  // 4) Overall pass/fail: by default if ANY unit fails => fail
  const overallPassed = failingUnits === 0;

  const outputStats = {
    unitsRun: plan.length,
    failingUnits,
    totalRows,
    rowCapPerUnit: rowCap,
    timeoutMs,
  };

  const outputSummary = overallPassed
    ? `PASS (${plan.length} unit(s), 0 failing, ${totalRows} total rows)`
    : `FAIL (${plan.length} unit(s), ${failingUnits} failing, ${totalRows} total rows) • ` +
      unitSummaries.slice(0, 6).join(' | ') +
      (unitSummaries.length > 6 ? ` | +${unitSummaries.length - 6} more…` : '');

  // 5) Violations count = totalRows when failing, else 0
  return {
    status: overallPassed ? 'pass' : 'fail',
    violationsCount: overallPassed ? 0 : totalRows,
    outputSummary,
    outputStats,
    outputRows: sampleRows,
    targetRefs: targets,
  };
}


---

4) Integrate into /run runner (drop-in change)

In your checklist runner where you currently do the “SQL check” branch, replace it with runSqlNode().

Patch in apps/api/src/checklist/runner.ts

import { runSqlNode } from '../sqlrunner/runSqlNode';

// inside item loop, when item.check_kind === 'sql'
const out = await runSqlNode({
  targetPool,
  sqlTemplate: item.sql_template,
  schemas,
  scopeType: item.scope_type ?? 'diagram',
  targetSelector: (item.target_selector ?? null) as any,
  passFailRule: item.pass_fail_rule ?? null,
  resultMapping: (item.result_mapping ?? null) as any,
  limits: { timeoutMs: 2500, rowCap: 50 },
  thresholds: (item.thresholds ?? {}) as any, // optional if you store
  vars: {}, // optional
});

violationsCount = out.violationsCount;
outputSummary = out.outputSummary;
outputStats = out.outputStats;
outputRows = out.outputRows;
targetRefs = out.targetRefs;

And make sure your query is selecting:

scope_type

target_selector

pass_fail_rule

result_mapping

sql_template



---

5) Recommended node JSON patterns (so builder can produce them)

Table-scoped SQL check (runs once per table)

{
  "scopeType": "table",
  "targetSelector": { "kind": "allTables" },
  "passFailRule": { "type": "rowCount", "max": 0 },
  "resultMapping": { "targetKind": "table", "fields": { "schema": "schema", "table": "table" } }
}

Schema-scoped SQL check (runs once per schema)

{
  "scopeType": "schema",
  "targetSelector": { "kind": "allSchemas" },
  "passFailRule": { "type": "rowCount", "max": 0 }
}

Regex table selection

{
  "scopeType": "table",
  "targetSelector": { "kind": "tablesByRegex", "pattern": "^dim_" }
}


---

6) What you get immediately

SQL checks can target each table and produce table-level target_ref → your Issues Drawer and ERD Annotations become way more accurate.

Your builder can now create checks like:

missing PK per table

missing indexes on FK cols

naming conventions by regex

column nullability rules




---

Next thing I’d ship (after scope iteration)

2.2 Issues filters + sort (blocking first, filters by schema/table/section) — because once you start generating lots of results, the UI needs a clean queue.

If you want, say “2.2 issues filters code” and I’ll drop the exact SQL + Fastify handler.
